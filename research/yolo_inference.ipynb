{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06d9261e",
   "metadata": {},
   "source": [
    "### Object detection on images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "205f32e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "person -> 0.9963330626487732\n",
      "book -> 0.7454584240913391\n",
      "book -> 0.7102881073951721\n",
      "book -> 0.6613765358924866\n",
      "book -> 0.642610490322113\n",
      "book -> 0.6321038007736206\n",
      "book -> 0.6220565438270569\n",
      "book -> 0.5905422568321228\n",
      "book -> 0.588641881942749\n",
      "book -> 0.5483890771865845\n",
      "book -> 0.5480033159255981\n",
      "book -> 0.5449872612953186\n",
      "book -> 0.5108945369720459\n"
     ]
    }
   ],
   "source": [
    "### import necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### model paths\n",
    "coco_data_path = '/home/pallav/yolo/models/coco.names'\n",
    "yolo_cfg_path = '/home/pallav/yolo/models/yolov3.cfg'\n",
    "yolo_wts_path = '/home/pallav/yolo/models/yolov3.weights'\n",
    "\n",
    "### image path\n",
    "img_path = '/home/pallav/Downloads/02.jpg'\n",
    "\n",
    "\n",
    "### read classnames from coco.names file\n",
    "LABELS = open(coco_data_path).read().strip().split('\\n')\n",
    "\n",
    "## initialize a list of colors to represent each possible class label\n",
    "np.random.seed(42)\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")\n",
    "\n",
    "### load the object detector\n",
    "net = cv2.dnn.readNetFromDarknet(yolo_cfg_path, yolo_wts_path)\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "### read frame of video for object detection\n",
    "frame = cv2.imread(img_path)\n",
    "(H, W) = frame.shape[:2]\n",
    "\n",
    "# YOLO object detector - obtain bounding boxes and probabilities\n",
    "blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "net.setInput(blob)\n",
    "layerOutputs = net.forward(ln)\n",
    "\n",
    "# initialize our lists of detected bounding boxes, confidences, and class ID\n",
    "boxes = []\n",
    "confidences = []\n",
    "classIDs = []\n",
    "\n",
    "# loop over each of the layer outputs\n",
    "for output in layerOutputs:\n",
    "    # loop over each of the detections\n",
    "    for detection in output:\n",
    "        # extract the class ID and confidence (i.e., probability)\n",
    "        # of the current object detection\n",
    "        scores = detection[5:]\n",
    "        classID = np.argmax(scores)\n",
    "        confidence = scores[classID]\n",
    "        if confidence > 0.5:\n",
    "            # scale the bounding box coordinates back relative to the size of the image\n",
    "            # YOLO model returns the center (x, y)-coordinates of\n",
    "            # the bounding box followed by the boxes' width and height\n",
    "            box = detection[0:4] * np.array([W, H, W, H])\n",
    "            (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "            \n",
    "            # use the center (x, y)-coordinates to derive the top and and left corner of the bounding box\n",
    "            x = int(centerX - (width / 2))\n",
    "            y = int(centerY - (height / 2))\n",
    "            \n",
    "            # update our list of bounding box coordinates, confidences, and class IDs\n",
    "            boxes.append([x, y, int(width), int(height)])\n",
    "            confidences.append(float(confidence))\n",
    "            classIDs.append(classID)\n",
    "            \n",
    "# apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.3)\n",
    "\n",
    "#  ensure at least one detection exists\n",
    "if len(idxs) > 0:\n",
    "    # loop over the indexes \n",
    "    for i in idxs.flatten():\n",
    "        # extract the bounding box coordinates\n",
    "        (x, y) = (boxes[i][0], boxes[i][1])\n",
    "        (w, h) = (boxes[i][2], boxes[i][3])\n",
    "        # draw a bounding box rectangle and label on the frame\n",
    "        color = [int(c) for c in COLORS[classIDs[i]]]\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "        text = \"{}: {:.4f}\".format(LABELS[classIDs[i]], confidences[i])\n",
    "#         print the labels and confidence\n",
    "#         print(video_name + f\"_frame_{count}.jpg\")\n",
    "        print(f\"{LABELS[classIDs[i]]} -> {str(confidences[i])}\")\n",
    "        cv2.putText(frame, text, (x, y - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2dc8aa5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d2d1220",
   "metadata": {},
   "source": [
    "### Object detection on videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3726c03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import necessary libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### model paths\n",
    "coco_data_path = '/home/pallav/yolo/models/coco.names'\n",
    "yolo_cfg_path = '/home/pallav/yolo/models/yolov3.cfg'\n",
    "yolo_wts_path = '/home/pallav/yolo/models/yolov3.weights'\n",
    "\n",
    "### read classnames from coco.names file\n",
    "LABELS = open(coco_data_path).read().strip().split('\\n')\n",
    "\n",
    "## initialize a list of colors to represent each possible class label\n",
    "np.random.seed(42)\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")\n",
    "\n",
    "### load the object detector\n",
    "net = cv2.dnn.readNetFromDarknet(yolo_cfg_path, yolo_wts_path)\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i - 1] for i in net.getUnconnectedOutLayers()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a917b27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Name = 8832-1663935392-1675159794.mp4\tTotal frames = 211\n",
      "8832-1663935392-1675159794.mp4_frame_1.jpg\n",
      "8832-1663935392-1675159794.mp4_frame_16.0.jpg\n",
      "8832-1663935392-1675159794.mp4_frame_31.0.jpg\n",
      "orange -> 0.42128127813339233\n",
      "8832-1663935392-1675159794.mp4_frame_46.0.jpg\n",
      "8832-1663935392-1675159794.mp4_frame_61.0.jpg\n",
      "8832-1663935392-1675159794.mp4_frame_76.0.jpg\n",
      "8832-1663935392-1675159794.mp4_frame_91.0.jpg\n",
      "8832-1663935392-1675159794.mp4_frame_106.0.jpg\n",
      "8832-1663935392-1675159794.mp4_frame_121.0.jpg\n",
      "8832-1663935392-1675159794.mp4_frame_136.0.jpg\n",
      "8832-1663935392-1675159794.mp4_frame_151.0.jpg\n",
      "8832-1663935392-1675159794.mp4_frame_166.0.jpg\n",
      "8832-1663935392-1675159794.mp4_frame_181.0.jpg\n",
      "8832-1663935392-1675159794.mp4_frame_196.0.jpg\n"
     ]
    }
   ],
   "source": [
    "### image path\n",
    "vid_dir_path = 'https://wkcdn.wakau.in/wakau/videoContent/'\n",
    "vid_name = '8832-1663935392-1675159794.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(vid_dir_path + vid_name)\n",
    "(W, H) = (None, None)\n",
    "\n",
    "# Find the total number of frames in the video file\n",
    "total_frame = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"Video Name = {vid_name}\\tTotal frames = {total_frame}\")\n",
    "\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)  # Gets the frames per second\n",
    "multiplier = fps * 0.50\n",
    "frame_counter = 1\n",
    "\n",
    "vid_result = []\n",
    "predictions = {}\n",
    "\n",
    "while frame_counter <= total_frame:\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, frame_counter)\n",
    "    (grabbed, frame) = cap.read()\n",
    "    frame_no = frame_counter\n",
    "    frame_counter += multiplier\n",
    "    # if the frame was not grabbed, then we have reached the end of the stream\n",
    "    if not grabbed:\n",
    "        break\n",
    "    # if the frame dimensions are empty, grab them\n",
    "    if W is None or H is None:\n",
    "        (H, W) = frame.shape[:2]\n",
    "    \n",
    "    # YOLO object detector - obtain bounding boxes and probabilities\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (416, 416), swapRB=True, crop=False)\n",
    "    net.setInput(blob)\n",
    "    layerOutputs = net.forward(ln)\n",
    "\n",
    "    # initialize our lists of detected bounding boxes, confidences, and class ID\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "    classIDs = []\n",
    "\n",
    "    # loop over each of the layer outputs\n",
    "    for output in layerOutputs:\n",
    "        # loop over each of the detections\n",
    "        for detection in output:\n",
    "            # extract the class ID and confidence (i.e., probability)\n",
    "            # of the current object detection\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "            if confidence > 0.3:\n",
    "                # scale the bounding box coordinates back relative to the size of the image\n",
    "                # YOLO model returns the center (x, y)-coordinates of\n",
    "                # the bounding box followed by the boxes' width and height\n",
    "                box = detection[0:4] * np.array([W, H, W, H])\n",
    "                (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "\n",
    "                # use the center (x, y)-coordinates to derive the top and and left corner of the bounding box\n",
    "                x = int(centerX - (width / 2))\n",
    "                y = int(centerY - (height / 2))\n",
    "\n",
    "                # update our list of bounding box coordinates, confidences, and class IDs\n",
    "                boxes.append([x, y, int(width), int(height)])\n",
    "                confidences.append(float(confidence))\n",
    "                classIDs.append(classID)\n",
    "\n",
    "    # apply non-maxima suppression to suppress weak, overlapping bounding boxes\n",
    "    idxs = cv2.dnn.NMSBoxes(boxes, confidences, 0.3, 0.3)\n",
    "\n",
    "\n",
    "    print(vid_name + f\"_frame_{frame_no}.jpg\")\n",
    "\n",
    "    #  ensure at least one detection exists\n",
    "    if len(idxs) > 0:\n",
    "        # loop over the indexes \n",
    "        for i in idxs.flatten():\n",
    "            predictions[LABELS[classIDs[i]]] = round(confidences[0], 2)\n",
    "            print(f\"{LABELS[classIDs[i]]} -> {str(confidences[i])}\")\n",
    "\n",
    "#     ## change logic\n",
    "#     frame_result.append([vid_name, f\"frame_{int(frame_no)}\", predictions])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e931e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1544fa94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: {'bowl': 0.4, 'diningtable': 0.9, 'vase': 0.6, 'person': 0.9}\n",
      "\n",
      "After: {'bowl': 0.4, 'diningtable': 0.95, 'vase': 0.6, 'person': 0.9}\n"
     ]
    }
   ],
   "source": [
    "predictions = {'bowl': 0.4, 'diningtable': 0.9, 'vase': 0.6, 'person': 0.9}\n",
    "print(f\"Before: {predictions}\")\n",
    "\n",
    "label = 'diningtable'\n",
    "confidence = 0.95\n",
    "if label in predictions.keys():\n",
    "    predictions[label] = max(predictions[label], confidence)\n",
    "else:\n",
    "    predictions[label] = confidence\n",
    "    \n",
    "print(f\"\\nAfter: {predictions}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370d42f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9091030",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8be16e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d9b3de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3d9402",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419f317a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person', 'bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "### model paths\n",
    "coco_data_path = '/home/pallav/yolo/models/coco.names'\n",
    "yolo_cfg_path = '/home/pallav/yolo/models/yolov3.cfg'\n",
    "yolo_wts_path = '/home/pallav/yolo/models/yolov3.weights'\n",
    "\n",
    "### read classnames from coco.names file\n",
    "LABELS = open(coco_data_path).read().strip().split('\\n')\n",
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "069276f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_label_dict = {\n",
    "    'food' : ['banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake'],\n",
    "    'automobiles' : ['bicycle', 'car', 'motorbike', 'aeroplane', 'bus', 'train', 'truck', 'boat'],\n",
    "    'sports_items' : ['frisbee', 'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard', 'tennis racket'],\n",
    "    'animals' : ['bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe'],\n",
    "    'household_items' : ['chair', 'sofa', 'pottedplant', 'bed', 'diningtable', 'toilet', 'tvmonitor', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush'],\n",
    "    'kitchen_items' : ['microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl'],\n",
    "    'other_items' : ['backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'fire hydrant', 'stop sign', 'parking meter', 'bench']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e44b4339",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {'person': 0.983, 'hot dog': 0.992, 'diningtable': 0.854, 'bowl': 0.786, 'spoon': 0.581, 'oven': 0.954, 'sink': 0.555, 'bottle': 0.949}\n",
    "master_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd104035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in result.keys():\n",
    "#     if i in master_label_dict['food']:\n",
    "#         master_list.append('food')\n",
    "#     if i in master_label_dict['automobiles']:\n",
    "#         master_list.append('automobiles')\n",
    "#     if i in master_label_dict['sports_items']:\n",
    "#         master_list.append('sports_items')\n",
    "#     if i in master_label_dict['animals']:\n",
    "#         master_list.append('animals')\n",
    "#     if i in master_label_dict['household_items']:\n",
    "#         master_list.append('household_items')\n",
    "#     if i in master_label_dict['kitchen_items']:\n",
    "#         master_list.append('kitchen_items')\n",
    "#     if i in master_label_dict['other_items']:\n",
    "#         master_list.append('other_items')\n",
    "        \n",
    "        \n",
    "for label in result.keys():\n",
    "    for i in master_label_dict.keys():\n",
    "        if label in master_label_dict[i]:\n",
    "            master_list.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "688654c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['household_items', 'kitchen_items', 'food']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(master_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61200966",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['household_items', 'kitchen_items', 'food']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(master_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bbb7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f50b234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data: (88230, 2)\n",
      "Columns in data: Index(['_id', 'contentURL'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('/home/pallav/yolo/backend_content_details.csv', low_memory = False)\n",
    "data = data[['_id', 'contentURL']]\n",
    "data = data.drop_duplicates()\n",
    "data = data.dropna()\n",
    "print(f\"Shape of data: {data.shape}\")\n",
    "print(f\"Columns in data: {data.columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98a507fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "https://wkcdn.wakau.in/wakau/videoContent/4262-1674247688-1675160133.mp4\n",
      "63d8ea45706187554a72a723\n"
     ]
    }
   ],
   "source": [
    "for index, i in data.iterrows():\n",
    "    print(index)\n",
    "    print(i['contentURL'])\n",
    "    print(i['_id'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "54aef645",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, _id                                    63d8ea45706187554a72a723\n",
      "contentURL    https://wkcdn.wakau.in/wakau/videoContent/4262...\n",
      "Name: 0, dtype: object)\n"
     ]
    }
   ],
   "source": [
    "for i in data.iterrows():\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1595974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2cedd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6c320e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
